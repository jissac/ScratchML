{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Fashion_GAN.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"yC5I4tRWzIQP","colab_type":"code","colab":{}},"cell_type":"code","source":["# import relevant libraries\n","%matplotlib inline\n","import pickle as pkl\n","import numpy as np\n","import tensorflow as tf\n","import matplotlib.pyplot as plt"],"execution_count":0,"outputs":[]},{"metadata":{"id":"LoHAciw3Dtw7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"b307cf3c-e862-431c-e1bd-3ebd9f8707e0","executionInfo":{"status":"ok","timestamp":1537319975140,"user_tz":240,"elapsed":1808,"user":{"displayName":"James Issac","photoUrl":"//lh3.googleusercontent.com/-vVqphNlJNfg/AAAAAAAAAAI/AAAAAAAAH7M/Yj7sNhBd_ZA/s50-c-k-no/photo.jpg","userId":"109910308557783119284"}}},"cell_type":"code","source":["# confirm TensorFlow can see the GPU\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Found GPU at: /device:GPU:0\n"],"name":"stdout"}]},{"metadata":{"id":"1UsM71NTD07f","colab_type":"code","colab":{}},"cell_type":"code","source":["# load Fashion dataset\n","\n","from google.colab import files\n","\n","uploaded = files.upload()\n","\n","'''\n","files.upload() returns a dictionary of the files which were uploaded. The \n","dictionary is keyed by the file name, the value is the data which was \n","uploaded\n","\n","'''\n","\n","for fn in uploaded.keys():\n","  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n","      name=fn,length=len(uploaded[fn])))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"5b7QEftRzMS_","colab_type":"code","colab":{}},"cell_type":"code","source":["# load MNIST dataset\n","from tensorflow.examples.tutorials.mnist import input_data\n","mnist = input_data.read_data_sets('MNIST_data')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"vpuL3Ucnz5X4","colab_type":"code","colab":{}},"cell_type":"code","source":["'''\n","Create inputs for our graph. We'll have two inputs - one for the \n","generator (input_z) and one for the discriminator(inputs_real).\n","\n","'''\n","def model_inputs(real_dim, z_dim):\n","  inputs_real = tf.placeholder(tf.float32, (None, real_dim), name='input_real')\n","  inputs_z = tf.placeholder(tf.float32, (None, z_dim), name='input_z')\n","  \n","  return inputs_real, inputs_z"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-4wEf0AK0pqI","colab_type":"code","colab":{}},"cell_type":"code","source":["def generator(z,out_dim,n_units=128,reuse=False,alpha=0.01):\n","  with tf.variable_scope('generator', reuse=reuse):\n","    # Hidden layer\n","    h1 = tf.layers.dense(z,n_units,activation=None)\n","    # Leaky ReLU\n","    h1 = tf.maximum(alpha*h1,h1)\n","    \n","    # Logits and tanh output\n","    logits = tf.layers.dense(h1,out_dim,activation=None)\n","    out = tf.tanh(logits)\n","    \n","    return out"],"execution_count":0,"outputs":[]},{"metadata":{"id":"8F9LEs8NWH2G","colab_type":"code","colab":{}},"cell_type":"code","source":["def discriminator(x,n_units=128,reuse=False,alpha=0.01):\n","  with tf.variable_scope('discriminator',reuse=reuse):\n","    # Hidden layer\n","    h1 = tf.layers.dense(x,n_units,activation=None)\n","    # Leaky ReLU\n","    h1 = tf.maximum(alpha*h1,h1)\n","    \n","    # Logits and sigmoid output\n","    logits = tf.layers.dense(h1,1,activation=None)\n","    out = tf.sigmoid(logits)\n","    \n","    return out,logits"],"execution_count":0,"outputs":[]},{"metadata":{"id":"kxUbBsqMWxLR","colab_type":"code","colab":{}},"cell_type":"code","source":["''' HYPERPARAMETERS'''\n","\n","# Size of input image to discriminator\n","input_size = 784\n","# Size of latent vector to generator\n","z_size = 100\n","# Sizes of hidden layers in generator and discriminator\n","g_hidden_size = 128\n","d_hidden_size = 128\n","# Leak factor for leaky ReLU\n","alpha = 0.01\n","# Smoothing\n","smooth = 0.1"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Pbq5_APLXKQS","colab_type":"code","colab":{}},"cell_type":"code","source":["''' BUILDING NETWORK'''\n","tf.reset_default_graph()\n","# Create our input placeholders\n","input_real, input_z = model_inputs(input_size, z_size)\n","\n","# Build model, g_model is generator output\n","g_model = generator(input_z, input_size, n_units=g_hidden_size, alpha=alpha)\n","\n","d_model_real, d_logits_real = discriminator(input_real, n_units=d_hidden_size, alpha=alpha)\n","d_model_fake, d_logits_fake = discriminator(g_model, reuse=True, n_units=d_hidden_size,alpha=alpha)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"hLmKp-HlXxGR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1717},"outputId":"855a55ad-9599-49a9-dcd1-0e7bc05333d4","executionInfo":{"status":"ok","timestamp":1537320618302,"user_tz":240,"elapsed":314508,"user":{"displayName":"James Issac","photoUrl":"//lh3.googleusercontent.com/-vVqphNlJNfg/AAAAAAAAAAI/AAAAAAAAH7M/Yj7sNhBd_ZA/s50-c-k-no/photo.jpg","userId":"109910308557783119284"}}},"cell_type":"code","source":["''' CTrlv'''\n","\n","# Calculate losses\n","d_loss_real = tf.reduce_mean(\n","                  tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_real, \n","                                                          labels=tf.ones_like(d_logits_real) * (1 - smooth)))\n","d_loss_fake = tf.reduce_mean(\n","                  tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake, \n","                                                          labels=tf.zeros_like(d_logits_real)))\n","d_loss = d_loss_real + d_loss_fake\n","\n","g_loss = tf.reduce_mean(\n","             tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake,\n","                                                     labels=tf.ones_like(d_logits_fake)))\n","# Optimizers\n","learning_rate = 0.002\n","\n","# Get the trainable_variables, split into G and D parts\n","t_vars = tf.trainable_variables()\n","g_vars = [var for var in t_vars if var.name.startswith('generator')]\n","d_vars = [var for var in t_vars if var.name.startswith('discriminator')]\n","\n","d_train_opt = tf.train.AdamOptimizer(learning_rate).minimize(d_loss, var_list=d_vars)\n","g_train_opt = tf.train.AdamOptimizer(learning_rate).minimize(g_loss, var_list=g_vars)\n","\n","\n","batch_size = 100\n","epochs = 100\n","samples = []\n","losses = []\n","# Only save generator variables\n","saver = tf.train.Saver(var_list=g_vars)\n","with tf.Session() as sess:\n","    sess.run(tf.global_variables_initializer())\n","    for e in range(epochs):\n","        for ii in range(mnist.train.num_examples//batch_size):\n","            batch = mnist.train.next_batch(batch_size)\n","            \n","            # Get images, reshape and rescale to pass to D\n","            batch_images = batch[0].reshape((batch_size, 784))\n","            batch_images = batch_images*2 - 1\n","            \n","            # Sample random noise for G\n","            batch_z = np.random.uniform(-1, 1, size=(batch_size, z_size))\n","            \n","            # Run optimizers\n","            _ = sess.run(d_train_opt, feed_dict={input_real: batch_images, input_z: batch_z})\n","            _ = sess.run(g_train_opt, feed_dict={input_z: batch_z})\n","        \n","        # At the end of each epoch, get the losses and print them out\n","        train_loss_d = sess.run(d_loss, {input_z: batch_z, input_real: batch_images})\n","        train_loss_g = g_loss.eval({input_z: batch_z})\n","            \n","        print(\"Epoch {}/{}...\".format(e+1, epochs),\n","              \"Discriminator Loss: {:.4f}...\".format(train_loss_d),\n","              \"Generator Loss: {:.4f}\".format(train_loss_g))    \n","        # Save losses to view after training\n","        losses.append((train_loss_d, train_loss_g))\n","        \n","        # Sample from generator as we're training for viewing afterwards\n","        sample_z = np.random.uniform(-1, 1, size=(16, z_size))\n","        gen_samples = sess.run(\n","                       generator(input_z, input_size, n_units=g_hidden_size, reuse=True, alpha=alpha),\n","                       feed_dict={input_z: sample_z})\n","        samples.append(gen_samples)\n","        saver.save(sess, './checkpoints/generator.ckpt')\n","\n","# Save training generator samples\n","with open('train_samples.pkl', 'wb') as f:\n","    pkl.dump(samples, f)\n"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Epoch 1/100... Discriminator Loss: 0.3653... Generator Loss: 3.9091\n","Epoch 2/100... Discriminator Loss: 0.3904... Generator Loss: 3.7598\n","Epoch 3/100... Discriminator Loss: 0.4889... Generator Loss: 3.2077\n","Epoch 4/100... Discriminator Loss: 0.7346... Generator Loss: 3.1952\n","Epoch 5/100... Discriminator Loss: 3.2319... Generator Loss: 2.5451\n","Epoch 6/100... Discriminator Loss: 1.6714... Generator Loss: 1.6889\n","Epoch 7/100... Discriminator Loss: 1.8072... Generator Loss: 1.4677\n","Epoch 8/100... Discriminator Loss: 0.9690... Generator Loss: 1.5453\n","Epoch 9/100... Discriminator Loss: 0.7293... Generator Loss: 3.1458\n","Epoch 10/100... Discriminator Loss: 1.8963... Generator Loss: 1.8863\n","Epoch 11/100... Discriminator Loss: 0.7792... Generator Loss: 2.0302\n","Epoch 12/100... Discriminator Loss: 0.9301... Generator Loss: 2.3031\n","Epoch 13/100... Discriminator Loss: 1.4263... Generator Loss: 1.9884\n","Epoch 14/100... Discriminator Loss: 1.5954... Generator Loss: 1.5664\n","Epoch 15/100... Discriminator Loss: 1.2234... Generator Loss: 1.6029\n","Epoch 16/100... Discriminator Loss: 1.1938... Generator Loss: 1.4134\n","Epoch 17/100... Discriminator Loss: 1.0278... Generator Loss: 1.9971\n","Epoch 18/100... Discriminator Loss: 1.5803... Generator Loss: 1.6747\n","Epoch 19/100... Discriminator Loss: 1.2200... Generator Loss: 2.3069\n","Epoch 20/100... Discriminator Loss: 1.1615... Generator Loss: 2.1478\n","Epoch 21/100... Discriminator Loss: 1.3650... Generator Loss: 1.2822\n","Epoch 22/100... Discriminator Loss: 0.9949... Generator Loss: 1.8990\n","Epoch 23/100... Discriminator Loss: 0.9731... Generator Loss: 1.8254\n","Epoch 24/100... Discriminator Loss: 0.8544... Generator Loss: 2.0765\n","Epoch 25/100... Discriminator Loss: 0.8096... Generator Loss: 2.4054\n","Epoch 26/100... Discriminator Loss: 0.7820... Generator Loss: 2.1649\n","Epoch 27/100... Discriminator Loss: 0.8736... Generator Loss: 2.2296\n","Epoch 28/100... Discriminator Loss: 1.2391... Generator Loss: 1.9605\n","Epoch 29/100... Discriminator Loss: 0.9878... Generator Loss: 2.3954\n","Epoch 30/100... Discriminator Loss: 0.9059... Generator Loss: 2.2332\n","Epoch 31/100... Discriminator Loss: 1.0366... Generator Loss: 1.8865\n","Epoch 32/100... Discriminator Loss: 0.8611... Generator Loss: 2.7047\n","Epoch 33/100... Discriminator Loss: 1.0447... Generator Loss: 2.0569\n","Epoch 34/100... Discriminator Loss: 0.8894... Generator Loss: 2.2103\n","Epoch 35/100... Discriminator Loss: 1.0471... Generator Loss: 1.6276\n","Epoch 36/100... Discriminator Loss: 1.0149... Generator Loss: 2.1217\n","Epoch 37/100... Discriminator Loss: 1.1088... Generator Loss: 1.9720\n","Epoch 38/100... Discriminator Loss: 1.0681... Generator Loss: 1.6869\n","Epoch 39/100... Discriminator Loss: 1.0861... Generator Loss: 1.6257\n","Epoch 40/100... Discriminator Loss: 1.2221... Generator Loss: 1.8206\n","Epoch 41/100... Discriminator Loss: 1.0662... Generator Loss: 1.3046\n","Epoch 42/100... Discriminator Loss: 0.8929... Generator Loss: 2.1867\n","Epoch 43/100... Discriminator Loss: 0.8423... Generator Loss: 2.5971\n","Epoch 44/100... Discriminator Loss: 0.9934... Generator Loss: 2.1971\n","Epoch 45/100... Discriminator Loss: 1.0149... Generator Loss: 1.4365\n","Epoch 46/100... Discriminator Loss: 1.0692... Generator Loss: 2.4263\n","Epoch 47/100... Discriminator Loss: 1.0161... Generator Loss: 1.8746\n","Epoch 48/100... Discriminator Loss: 1.0627... Generator Loss: 1.9576\n","Epoch 49/100... Discriminator Loss: 0.8852... Generator Loss: 2.1795\n","Epoch 50/100... Discriminator Loss: 1.1838... Generator Loss: 1.9805\n","Epoch 51/100... Discriminator Loss: 0.9238... Generator Loss: 1.9827\n","Epoch 52/100... Discriminator Loss: 0.9583... Generator Loss: 1.9582\n","Epoch 53/100... Discriminator Loss: 1.0448... Generator Loss: 2.2572\n","Epoch 54/100... Discriminator Loss: 1.3457... Generator Loss: 1.3458\n","Epoch 55/100... Discriminator Loss: 0.9666... Generator Loss: 2.0821\n","Epoch 56/100... Discriminator Loss: 0.9571... Generator Loss: 1.7265\n","Epoch 57/100... Discriminator Loss: 0.9959... Generator Loss: 2.1517\n","Epoch 58/100... Discriminator Loss: 1.0957... Generator Loss: 1.5831\n","Epoch 59/100... Discriminator Loss: 0.9008... Generator Loss: 1.8739\n","Epoch 60/100... Discriminator Loss: 0.7637... Generator Loss: 2.1752\n","Epoch 61/100... Discriminator Loss: 0.9682... Generator Loss: 1.8898\n","Epoch 62/100... Discriminator Loss: 1.0852... Generator Loss: 1.4785\n","Epoch 63/100... Discriminator Loss: 1.0154... Generator Loss: 2.1319\n","Epoch 64/100... Discriminator Loss: 0.9083... Generator Loss: 1.9435\n","Epoch 65/100... Discriminator Loss: 0.9890... Generator Loss: 1.8003\n","Epoch 66/100... Discriminator Loss: 1.0180... Generator Loss: 1.3949\n","Epoch 67/100... Discriminator Loss: 0.9846... Generator Loss: 1.8011\n","Epoch 68/100... Discriminator Loss: 0.9944... Generator Loss: 2.1464\n","Epoch 69/100... Discriminator Loss: 0.9530... Generator Loss: 2.0848\n","Epoch 70/100... Discriminator Loss: 1.0834... Generator Loss: 1.6668\n","Epoch 71/100... Discriminator Loss: 1.0291... Generator Loss: 1.5474\n","Epoch 72/100... Discriminator Loss: 0.8696... Generator Loss: 2.2620\n","Epoch 73/100... Discriminator Loss: 1.1121... Generator Loss: 1.6645\n","Epoch 74/100... Discriminator Loss: 1.0187... Generator Loss: 1.7031\n","Epoch 75/100... Discriminator Loss: 0.9206... Generator Loss: 1.6694\n","Epoch 76/100... Discriminator Loss: 0.9378... Generator Loss: 1.8019\n","Epoch 77/100... Discriminator Loss: 0.9782... Generator Loss: 1.5304\n","Epoch 78/100... Discriminator Loss: 1.0803... Generator Loss: 1.7927\n","Epoch 79/100... Discriminator Loss: 1.0056... Generator Loss: 2.1802\n","Epoch 80/100... Discriminator Loss: 1.1240... Generator Loss: 1.3633\n","Epoch 81/100... Discriminator Loss: 0.9329... Generator Loss: 2.0196\n","Epoch 82/100... Discriminator Loss: 1.0076... Generator Loss: 1.5707\n","Epoch 83/100... Discriminator Loss: 0.9470... Generator Loss: 1.6200\n","Epoch 84/100... Discriminator Loss: 0.8966... Generator Loss: 1.8317\n","Epoch 85/100... Discriminator Loss: 0.9898... Generator Loss: 1.8214\n","Epoch 86/100... Discriminator Loss: 0.7499... Generator Loss: 1.9053\n","Epoch 87/100... Discriminator Loss: 0.9440... Generator Loss: 2.1576\n","Epoch 88/100... Discriminator Loss: 1.1045... Generator Loss: 1.5160\n","Epoch 89/100... Discriminator Loss: 1.0904... Generator Loss: 1.8369\n","Epoch 90/100... Discriminator Loss: 1.0212... Generator Loss: 1.6623\n","Epoch 91/100... Discriminator Loss: 0.9187... Generator Loss: 1.6601\n","Epoch 92/100... Discriminator Loss: 1.0066... Generator Loss: 1.7870\n","Epoch 93/100... Discriminator Loss: 0.8454... Generator Loss: 2.0380\n","Epoch 94/100... Discriminator Loss: 1.1041... Generator Loss: 1.4052\n","Epoch 95/100... Discriminator Loss: 1.0007... Generator Loss: 1.8644\n","Epoch 96/100... Discriminator Loss: 1.1833... Generator Loss: 1.1687\n","Epoch 97/100... Discriminator Loss: 0.8095... Generator Loss: 2.2335\n","Epoch 98/100... Discriminator Loss: 1.1293... Generator Loss: 1.5090\n","Epoch 99/100... Discriminator Loss: 0.9391... Generator Loss: 1.8505\n","Epoch 100/100... Discriminator Loss: 0.9775... Generator Loss: 1.6770\n"],"name":"stdout"}]},{"metadata":{"id":"PV9n-CjwZ-wU","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}