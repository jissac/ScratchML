{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris Dataset - Logistic Regression\n",
    "\n",
    "In this Jupyter notebook we'll look at the classic Iris dataset and use it to train a logistic regression classifier using Scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libaries\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris Plants Database\n",
      "====================\n",
      "\n",
      "Notes\n",
      "-----\n",
      "Data Set Characteristics:\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20  0.76     0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "This is a copy of UCI ML iris datasets.\n",
      "http://archive.ics.uci.edu/ml/datasets/Iris\n",
      "\n",
      "The famous Iris database, first used by Sir R.A Fisher\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      "References\n",
      "----------\n",
      "   - Fisher,R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda,R.O., & Hart,P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n",
      "\n",
      "Iris dataset keys: ['target_names', 'data', 'target', 'DESCR', 'feature_names']\n"
     ]
    }
   ],
   "source": [
    "# load and describe Iris data\n",
    "iris = datasets.load_iris()\n",
    "print(iris.DESCR)\n",
    "print('Iris dataset keys: {}'.format(list(iris.keys())))\n",
    "#print('Target/class names: {}'.format(iris.target_names))\n",
    "#print('Feature names: {}'.format(iris.feature_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.4],\n",
       "       [1.4],\n",
       "       [1.3],\n",
       "       [1.5],\n",
       "       [1.4],\n",
       "       [1.7],\n",
       "       [1.4],\n",
       "       [1.5],\n",
       "       [1.4],\n",
       "       [1.5],\n",
       "       [1.5],\n",
       "       [1.6],\n",
       "       [1.4],\n",
       "       [1.1],\n",
       "       [1.2],\n",
       "       [1.5],\n",
       "       [1.3],\n",
       "       [1.4],\n",
       "       [1.7],\n",
       "       [1.5],\n",
       "       [1.7],\n",
       "       [1.5],\n",
       "       [1. ],\n",
       "       [1.7],\n",
       "       [1.9],\n",
       "       [1.6],\n",
       "       [1.6],\n",
       "       [1.5],\n",
       "       [1.4],\n",
       "       [1.6],\n",
       "       [1.6],\n",
       "       [1.5],\n",
       "       [1.5],\n",
       "       [1.4],\n",
       "       [1.5],\n",
       "       [1.2],\n",
       "       [1.3],\n",
       "       [1.5],\n",
       "       [1.3],\n",
       "       [1.5],\n",
       "       [1.3],\n",
       "       [1.3],\n",
       "       [1.3],\n",
       "       [1.6],\n",
       "       [1.9],\n",
       "       [1.4],\n",
       "       [1.6],\n",
       "       [1.4],\n",
       "       [1.5],\n",
       "       [1.4],\n",
       "       [4.7],\n",
       "       [4.5],\n",
       "       [4.9],\n",
       "       [4. ],\n",
       "       [4.6],\n",
       "       [4.5],\n",
       "       [4.7],\n",
       "       [3.3],\n",
       "       [4.6],\n",
       "       [3.9],\n",
       "       [3.5],\n",
       "       [4.2],\n",
       "       [4. ],\n",
       "       [4.7],\n",
       "       [3.6],\n",
       "       [4.4],\n",
       "       [4.5],\n",
       "       [4.1],\n",
       "       [4.5],\n",
       "       [3.9],\n",
       "       [4.8],\n",
       "       [4. ],\n",
       "       [4.9],\n",
       "       [4.7],\n",
       "       [4.3],\n",
       "       [4.4],\n",
       "       [4.8],\n",
       "       [5. ],\n",
       "       [4.5],\n",
       "       [3.5],\n",
       "       [3.8],\n",
       "       [3.7],\n",
       "       [3.9],\n",
       "       [5.1],\n",
       "       [4.5],\n",
       "       [4.5],\n",
       "       [4.7],\n",
       "       [4.4],\n",
       "       [4.1],\n",
       "       [4. ],\n",
       "       [4.4],\n",
       "       [4.6],\n",
       "       [4. ],\n",
       "       [3.3],\n",
       "       [4.2],\n",
       "       [4.2],\n",
       "       [4.2],\n",
       "       [4.3],\n",
       "       [3. ],\n",
       "       [4.1],\n",
       "       [6. ],\n",
       "       [5.1],\n",
       "       [5.9],\n",
       "       [5.6],\n",
       "       [5.8],\n",
       "       [6.6],\n",
       "       [4.5],\n",
       "       [6.3],\n",
       "       [5.8],\n",
       "       [6.1],\n",
       "       [5.1],\n",
       "       [5.3],\n",
       "       [5.5],\n",
       "       [5. ],\n",
       "       [5.1],\n",
       "       [5.3],\n",
       "       [5.5],\n",
       "       [6.7],\n",
       "       [6.9],\n",
       "       [5. ],\n",
       "       [5.7],\n",
       "       [4.9],\n",
       "       [6.7],\n",
       "       [4.9],\n",
       "       [5.7],\n",
       "       [6. ],\n",
       "       [4.8],\n",
       "       [4.9],\n",
       "       [5.6],\n",
       "       [5.8],\n",
       "       [6.1],\n",
       "       [6.4],\n",
       "       [5.6],\n",
       "       [5.1],\n",
       "       [5.6],\n",
       "       [6.1],\n",
       "       [5.6],\n",
       "       [5.5],\n",
       "       [4.8],\n",
       "       [5.4],\n",
       "       [5.6],\n",
       "       [5.1],\n",
       "       [5.1],\n",
       "       [5.9],\n",
       "       [5.7],\n",
       "       [5.2],\n",
       "       [5. ],\n",
       "       [5.2],\n",
       "       [5.4],\n",
       "       [5.1]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris['data'][:,2:3] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (150, 1)\n",
      "Y shape: (150,)\n",
      "(array([[0.2],\n",
      "       [0.2],\n",
      "       [0.2],\n",
      "       [0.2],\n",
      "       [0.2],\n",
      "       [0.4],\n",
      "       [0.3],\n",
      "       [0.2],\n",
      "       [0.2],\n",
      "       [0.1],\n",
      "       [0.2],\n",
      "       [0.2],\n",
      "       [0.1],\n",
      "       [0.1],\n",
      "       [0.2],\n",
      "       [0.4],\n",
      "       [0.4],\n",
      "       [0.3],\n",
      "       [0.3],\n",
      "       [0.3],\n",
      "       [0.2],\n",
      "       [0.4],\n",
      "       [0.2],\n",
      "       [0.5],\n",
      "       [0.2],\n",
      "       [0.2],\n",
      "       [0.4],\n",
      "       [0.2],\n",
      "       [0.2],\n",
      "       [0.2],\n",
      "       [0.2],\n",
      "       [0.4],\n",
      "       [0.1],\n",
      "       [0.2],\n",
      "       [0.1],\n",
      "       [0.2],\n",
      "       [0.2],\n",
      "       [0.1],\n",
      "       [0.2],\n",
      "       [0.2],\n",
      "       [0.3],\n",
      "       [0.3],\n",
      "       [0.2],\n",
      "       [0.6],\n",
      "       [0.4],\n",
      "       [0.3],\n",
      "       [0.2],\n",
      "       [0.2],\n",
      "       [0.2],\n",
      "       [0.2],\n",
      "       [1.4],\n",
      "       [1.5],\n",
      "       [1.5],\n",
      "       [1.3],\n",
      "       [1.5],\n",
      "       [1.3],\n",
      "       [1.6],\n",
      "       [1. ],\n",
      "       [1.3],\n",
      "       [1.4],\n",
      "       [1. ],\n",
      "       [1.5],\n",
      "       [1. ],\n",
      "       [1.4],\n",
      "       [1.3],\n",
      "       [1.4],\n",
      "       [1.5],\n",
      "       [1. ],\n",
      "       [1.5],\n",
      "       [1.1],\n",
      "       [1.8],\n",
      "       [1.3],\n",
      "       [1.5],\n",
      "       [1.2],\n",
      "       [1.3],\n",
      "       [1.4],\n",
      "       [1.4],\n",
      "       [1.7],\n",
      "       [1.5],\n",
      "       [1. ],\n",
      "       [1.1],\n",
      "       [1. ],\n",
      "       [1.2],\n",
      "       [1.6],\n",
      "       [1.5],\n",
      "       [1.6],\n",
      "       [1.5],\n",
      "       [1.3],\n",
      "       [1.3],\n",
      "       [1.3],\n",
      "       [1.2],\n",
      "       [1.4],\n",
      "       [1.2],\n",
      "       [1. ],\n",
      "       [1.3],\n",
      "       [1.2],\n",
      "       [1.3],\n",
      "       [1.3],\n",
      "       [1.1],\n",
      "       [1.3],\n",
      "       [2.5],\n",
      "       [1.9],\n",
      "       [2.1],\n",
      "       [1.8],\n",
      "       [2.2],\n",
      "       [2.1],\n",
      "       [1.7],\n",
      "       [1.8],\n",
      "       [1.8],\n",
      "       [2.5],\n",
      "       [2. ],\n",
      "       [1.9],\n",
      "       [2.1],\n",
      "       [2. ],\n",
      "       [2.4],\n",
      "       [2.3],\n",
      "       [1.8],\n",
      "       [2.2],\n",
      "       [2.3],\n",
      "       [1.5],\n",
      "       [2.3],\n",
      "       [2. ],\n",
      "       [2. ],\n",
      "       [1.8],\n",
      "       [2.1],\n",
      "       [1.8],\n",
      "       [1.8],\n",
      "       [1.8],\n",
      "       [2.1],\n",
      "       [1.6],\n",
      "       [1.9],\n",
      "       [2. ],\n",
      "       [2.2],\n",
      "       [1.5],\n",
      "       [1.4],\n",
      "       [2.3],\n",
      "       [2.4],\n",
      "       [1.8],\n",
      "       [1.8],\n",
      "       [2.1],\n",
      "       [2.4],\n",
      "       [2.3],\n",
      "       [1.9],\n",
      "       [2.3],\n",
      "       [2.5],\n",
      "       [2.3],\n",
      "       [1.9],\n",
      "       [2. ],\n",
      "       [2.3],\n",
      "       [1.8]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]))\n"
     ]
    }
   ],
   "source": [
    "# assign features and labels\n",
    "X = iris[\"data\"][:,3:] # petal length\n",
    "Y = (iris[\"target\"] == 1).astype(np.int) # Iris Versicolour = 1\n",
    "print('X shape: {}'.format(X.shape))\n",
    "print('Y shape: {}'.format(Y.shape))\n",
    "print(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic regression using scikit-learn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7264958 , 0.2735042 ],\n",
       "       [0.72634303, 0.27365697],\n",
       "       [0.72619021, 0.27380979],\n",
       "       ...,\n",
       "       [0.55243844, 0.44756156],\n",
       "       [0.55224837, 0.44775163],\n",
       "       [0.55205829, 0.44794171]])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba = log_reg.predict_proba(X_new)\n",
    "y_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.32718588 0.3275244  0.3278631  0.32820199 0.32854105 0.32888029\n",
      " 0.3292197  0.3295593  0.32989908 0.33023903 0.33057916 0.33091947\n",
      " 0.33125995 0.33160061 0.33194145 0.33228246 0.33262365 0.33296502\n",
      " 0.33330656 0.33364827 0.33399016 0.33433223 0.33467447 0.33501688\n",
      " 0.33535947 0.33570223 0.33604516 0.33638827 0.33673155 0.337075\n",
      " 0.33741862 0.33776242 0.33810638 0.33845052 0.33879483 0.33913931\n",
      " 0.33948396 0.33982878 0.34017377 0.34051893 0.34086426 0.34120976\n",
      " 0.34155543 0.34190126 0.34224727 0.34259344 0.34293978 0.34328628\n",
      " 0.34363296 0.3439798  0.3443268  0.34467398 0.34502132 0.34536882\n",
      " 0.34571649 0.34606432 0.34641232 0.34676049 0.34710881 0.3474573\n",
      " 0.34780596 0.34815478 0.34850376 0.3488529  0.34920221 0.34955167\n",
      " 0.3499013  0.35025109 0.35060105 0.35095116 0.35130143 0.35165187\n",
      " 0.35200246 0.35235321 0.35270412 0.3530552  0.35340643 0.35375781\n",
      " 0.35410936 0.35446106 0.35481292 0.35516494 0.35551712 0.35586945\n",
      " 0.35622194 0.35657458 0.35692738 0.35728034 0.35763344 0.35798671\n",
      " 0.35834013 0.3586937  0.35904743 0.3594013  0.35975534 0.36010952\n",
      " 0.36046386 0.36081835 0.36117299 0.36152778 0.36188273 0.36223782\n",
      " 0.36259307 0.36294846 0.36330401 0.3636597  0.36401554 0.36437154\n",
      " 0.36472768 0.36508397 0.3654404  0.36579699 0.36615372 0.3665106\n",
      " 0.36686762 0.36722479 0.36758211 0.36793957 0.36829718 0.36865493\n",
      " 0.36901283 0.36937087 0.36972905 0.37008738 0.37044585 0.37080447\n",
      " 0.37116322 0.37152212 0.37188116 0.37224035 0.37259967 0.37295913\n",
      " 0.37331874 0.37367848 0.37403837 0.37439839 0.37475856 0.37511886\n",
      " 0.3754793  0.37583987 0.37620059 0.37656144 0.37692243 0.37728356\n",
      " 0.37764482 0.37800622 0.37836776 0.37872943 0.37909123 0.37945317\n",
      " 0.37981524 0.38017745 0.38053979 0.38090227 0.38126487 0.38162761\n",
      " 0.38199048 0.38235348 0.38271662 0.38307988 0.38344328 0.38380681\n",
      " 0.38417046 0.38453425 0.38489816 0.3852622  0.38562638 0.38599068\n",
      " 0.3863551  0.38671966 0.38708434 0.38744915 0.38781408 0.38817914\n",
      " 0.38854433 0.38890964 0.38927508 0.38964064 0.39000632 0.39037213\n",
      " 0.39073806 0.39110412 0.3914703  0.3918366  0.39220302 0.39256956\n",
      " 0.39293622 0.39330301 0.39366991 0.39403694 0.39440408 0.39477135\n",
      " 0.39513873 0.39550623 0.39587385 0.39624159 0.39660944 0.39697741\n",
      " 0.3973455  0.39771371 0.39808203 0.39845046 0.39881901 0.39918768\n",
      " 0.39955646 0.39992535 0.40029436 0.40066348 0.40103271 0.40140205\n",
      " 0.40177151 0.40214108 0.40251076 0.40288055 0.40325045 0.40362046\n",
      " 0.40399058 0.40436081 0.40473115 0.4051016  0.40547216 0.40584282\n",
      " 0.40621359 0.40658447 0.40695545 0.40732654 0.40769774 0.40806904\n",
      " 0.40844045 0.40881196 0.40918357 0.40955529 0.40992711 0.41029904\n",
      " 0.41067107 0.4110432  0.41141543 0.41178776 0.4121602  0.41253273\n",
      " 0.41290537 0.4132781  0.41365094 0.41402387 0.4143969  0.41477003\n",
      " 0.41514326 0.41551658 0.41589001 0.41626353 0.41663714 0.41701085\n",
      " 0.41738466 0.41775856 0.41813255 0.41850664 0.41888083 0.41925511\n",
      " 0.41962948 0.42000394 0.42037849 0.42075314 0.42112788 0.42150271\n",
      " 0.42187762 0.42225263 0.42262773 0.42300292 0.4233782  0.42375356\n",
      " 0.42412902 0.42450456 0.42488018 0.4252559  0.4256317  0.42600759\n",
      " 0.42638356 0.42675962 0.42713576 0.42751199 0.4278883  0.42826469\n",
      " 0.42864117 0.42901773 0.42939437 0.42977109 0.4301479  0.43052478\n",
      " 0.43090175 0.4312788  0.43165592 0.43203313 0.43241041 0.43278778\n",
      " 0.43316522 0.43354274 0.43392033 0.434298   0.43467575 0.43505358\n",
      " 0.43543148 0.43580945 0.4361875  0.43656562 0.43694382 0.43732209\n",
      " 0.43770044 0.43807885 0.43845734 0.4388359  0.43921453 0.43959323\n",
      " 0.439972   0.44035085 0.44072976 0.44110874 0.44148779 0.44186691\n",
      " 0.44224609 0.44262534 0.44300466 0.44338405 0.4437635  0.44414302\n",
      " 0.4445226  0.44490225 0.44528196 0.44566174 0.44604158 0.44642148\n",
      " 0.44680144 0.44718147 0.44756156 0.44794171 0.44832192 0.44870219\n",
      " 0.44908252 0.44946291 0.44984336 0.45022387 0.45060444 0.45098506\n",
      " 0.45136575 0.45174648 0.45212728 0.45250813 0.45288904 0.45327\n",
      " 0.45365102 0.45403209 0.45441321 0.45479439 0.45517562 0.45555691\n",
      " 0.45593824 0.45631963 0.45670107 0.45708256 0.4574641  0.45784569\n",
      " 0.45822733 0.45860902 0.45899076 0.45937254 0.45975438 0.46013626\n",
      " 0.46051818 0.46090016 0.46128218 0.46166424 0.46204635 0.46242851\n",
      " 0.46281071 0.46319295 0.46357523 0.46395756 0.46433993 0.46472235\n",
      " 0.4651048  0.4654873  0.46586983 0.46625241 0.46663502 0.46701768\n",
      " 0.46740037 0.4677831  0.46816587 0.46854868 0.46893153 0.46931441\n",
      " 0.46969733 0.47008028 0.47046327 0.47084629 0.47122935 0.47161244\n",
      " 0.47199556 0.47237872 0.47276191 0.47314513 0.47352839 0.47391167\n",
      " 0.47429499 0.47467833 0.47506171 0.47544512 0.47582855 0.47621201\n",
      " 0.4765955  0.47697902 0.47736257 0.47774614 0.47812974 0.47851336\n",
      " 0.47889701 0.47928069 0.47966439 0.48004811 0.48043186 0.48081563\n",
      " 0.48119942 0.48158323 0.48196707 0.48235093 0.48273481 0.4831187\n",
      " 0.48350262 0.48388656 0.48427052 0.48465449 0.48503849 0.4854225\n",
      " 0.48580653 0.48619057 0.48657464 0.48695871 0.48734281 0.48772691\n",
      " 0.48811104 0.48849517 0.48887932 0.48926349 0.48964766 0.49003185\n",
      " 0.49041605 0.49080026 0.49118449 0.49156872 0.49195296 0.49233721\n",
      " 0.49272147 0.49310574 0.49349002 0.49387431 0.4942586  0.4946429\n",
      " 0.4950272  0.49541152 0.49579583 0.49618016 0.49656448 0.49694881\n",
      " 0.49733315 0.49771749 0.49810183 0.49848617 0.49887051 0.49925486\n",
      " 0.4996392  0.50002355 0.5004079  0.50079224 0.50117659 0.50156093\n",
      " 0.50194528 0.50232962 0.50271395 0.50309829 0.50348262 0.50386694\n",
      " 0.50425127 0.50463558 0.50501989 0.5054042  0.5057885  0.50617279\n",
      " 0.50655707 0.50694135 0.50732562 0.50770988 0.50809413 0.50847837\n",
      " 0.5088626  0.50924682 0.50963103 0.51001523 0.51039942 0.51078359\n",
      " 0.51116775 0.5115519  0.51193604 0.51232016 0.51270427 0.51308836\n",
      " 0.51347243 0.51385649 0.51424054 0.51462456 0.51500857 0.51539256\n",
      " 0.51577654 0.51616049 0.51654443 0.51692834 0.51731224 0.51769612\n",
      " 0.51807997 0.5184638  0.51884762 0.51923141 0.51961517 0.51999892\n",
      " 0.52038264 0.52076633 0.52115    0.52153365 0.52191727 0.52230087\n",
      " 0.52268444 0.52306798 0.5234515  0.52383498 0.52421844 0.52460187\n",
      " 0.52498527 0.52536865 0.52575199 0.5261353  0.52651858 0.52690183\n",
      " 0.52728505 0.52766824 0.52805139 0.52843451 0.5288176  0.52920065\n",
      " 0.52958367 0.52996666 0.5303496  0.53073252 0.53111539 0.53149823\n",
      " 0.53188104 0.5322638  0.53264653 0.53302922 0.53341187 0.53379448\n",
      " 0.53417705 0.53455958 0.53494207 0.53532452 0.53570693 0.5360893\n",
      " 0.53647162 0.5368539  0.53723614 0.53761833 0.53800048 0.53838258\n",
      " 0.53876464 0.53914666 0.53952862 0.53991055 0.54029242 0.54067425\n",
      " 0.54105603 0.54143776 0.54181944 0.54220107 0.54258266 0.54296419\n",
      " 0.54334568 0.54372711 0.54410849 0.54448982 0.5448711  0.54525232\n",
      " 0.5456335  0.54601462 0.54639568 0.54677669 0.54715765 0.54753855\n",
      " 0.54791939 0.54830018 0.54868091 0.54906159 0.5494422  0.54982276\n",
      " 0.55020327 0.55058371 0.55096409 0.55134442 0.55172468 0.55210488\n",
      " 0.55248503 0.55286511 0.55324513 0.55362508 0.55400498 0.55438481\n",
      " 0.55476458 0.55514428 0.55552392 0.5559035  0.55628301 0.55666245\n",
      " 0.55704183 0.55742114 0.55780038 0.55817956 0.55855867 0.55893771\n",
      " 0.55931668 0.55969558 0.56007442 0.56045318 0.56083187 0.5612105\n",
      " 0.56158905 0.56196753 0.56234594 0.56272427 0.56310253 0.56348072\n",
      " 0.56385883 0.56423687 0.56461484 0.56499273 0.56537055 0.56574829\n",
      " 0.56612595 0.56650353 0.56688104 0.56725847 0.56763583 0.5680131\n",
      " 0.5683903  0.56876741 0.56914445 0.56952141 0.56989828 0.57027508\n",
      " 0.57065179 0.57102842 0.57140497 0.57178144 0.57215782 0.57253413\n",
      " 0.57291034 0.57328647 0.57366252 0.57403848 0.57441436 0.57479015\n",
      " 0.57516585 0.57554147 0.575917   0.57629244 0.5766678  0.57704306\n",
      " 0.57741824 0.57779333 0.57816833 0.57854324 0.57891805 0.57929278\n",
      " 0.57966741 0.58004196 0.58041641 0.58079077 0.58116503 0.58153921\n",
      " 0.58191328 0.58228727 0.58266116 0.58303495 0.58340865 0.58378226\n",
      " 0.58415576 0.58452917 0.58490249 0.5852757  0.58564882 0.58602184\n",
      " 0.58639476 0.58676758 0.58714031 0.58751293 0.58788545 0.58825787\n",
      " 0.58863019 0.58900241 0.58937453 0.58974655 0.59011846 0.59049027\n",
      " 0.59086198 0.59123358 0.59160508 0.59197647 0.59234776 0.59271894\n",
      " 0.59309002 0.59346099 0.59383186 0.59420261 0.59457326 0.59494381\n",
      " 0.59531424 0.59568457 0.59605478 0.59642489 0.59679489 0.59716478\n",
      " 0.59753455 0.59790422 0.59827377 0.59864322 0.59901255 0.59938177\n",
      " 0.59975087 0.60011987 0.60048875 0.60085751 0.60122616 0.6015947\n",
      " 0.60196312 0.60233143 0.60269961 0.60306769 0.60343565 0.60380349\n",
      " 0.60417121 0.60453881 0.6049063  0.60527367 0.60564092 0.60600805\n",
      " 0.60637506 0.60674195 0.60710872 0.60747537 0.60784189 0.6082083\n",
      " 0.60857459 0.60894075 0.60930679 0.6096727  0.6100385  0.61040417\n",
      " 0.61076971 0.61113513 0.61150043 0.6118656  0.61223065 0.61259557\n",
      " 0.61296036 0.61332503 0.61368956 0.61405398 0.61441826 0.61478242\n",
      " 0.61514644 0.61551034 0.61587411 0.61623775 0.61660126 0.61696464\n",
      " 0.61732789 0.61769101 0.618054   0.61841685 0.61877957 0.61914216\n",
      " 0.61950462 0.61986695 0.62022914 0.62059119 0.62095312 0.6213149\n",
      " 0.62167656 0.62203807 0.62239946 0.6227607  0.62312181 0.62348279\n",
      " 0.62384362 0.62420432 0.62456488 0.62492531 0.62528559 0.62564574\n",
      " 0.62600574 0.62636561 0.62672534 0.62708493 0.62744437 0.62780368\n",
      " 0.62816284 0.62852187 0.62888075 0.62923949 0.62959809 0.62995654\n",
      " 0.63031485 0.63067302 0.63103104 0.63138892 0.63174665 0.63210424\n",
      " 0.63246169 0.63281899 0.63317614 0.63353315 0.63389001 0.63424672\n",
      " 0.63460329 0.63495971 0.63531598 0.6356721  0.63602807 0.6363839\n",
      " 0.63673957 0.6370951  0.63745048 0.6378057  0.63816078 0.63851571\n",
      " 0.63887048 0.6392251  0.63957957 0.63993389 0.64028806 0.64064207\n",
      " 0.64099593 0.64134964 0.64170319 0.64205659 0.64240984 0.64276293\n",
      " 0.64311586 0.64346864 0.64382127 0.64417374 0.64452605 0.64487821\n",
      " 0.64523021 0.64558205 0.64593373 0.64628526 0.64663663 0.64698784\n",
      " 0.64733889 0.64768978 0.64804052 0.64839109 0.6487415  0.64909176\n",
      " 0.64944185 0.64979178 0.65014155 0.65049116 0.65084061 0.6511899\n",
      " 0.65153902 0.65188798 0.65223678 0.65258541 0.65293388 0.65328219\n",
      " 0.65363033 0.65397831 0.65432613 0.65467378 0.65502126 0.65536858\n",
      " 0.65571573 0.65606272 0.65640954 0.65675619 0.65710268 0.65744899\n",
      " 0.65779515 0.65814113 0.65848694 0.65883259 0.65917807 0.65952338\n",
      " 0.65986852 0.66021348 0.66055828 0.66090291 0.66124737 0.66159166\n",
      " 0.66193578 0.66227972 0.6626235  0.6629671  0.66331053 0.66365379\n",
      " 0.66399688 0.66433979 0.66468253 0.66502509 0.66536748 0.6657097\n",
      " 0.66605175 0.66639362 0.66673531 0.66707683 0.66741817 0.66775934\n",
      " 0.66810033 0.66844115 0.66878179 0.66912225 0.66946253 0.66980264\n",
      " 0.67014257 0.67048233 0.6708219  0.6711613  0.67150052 0.67183955\n",
      " 0.67217842 0.6725171  0.6728556  0.67319392 0.67353206 0.67387002\n",
      " 0.6742078  0.6745454  0.67488282 0.67522005 0.67555711 0.67589398\n",
      " 0.67623067 0.67656718 0.67690351 0.67723965 0.67757561 0.67791139\n",
      " 0.67824698 0.67858239 0.67891762 0.67925266 0.67958751 0.67992218\n",
      " 0.68025667 0.68059097 0.68092508 0.68125901 0.68159276 0.68192631\n",
      " 0.68225968 0.68259287 0.68292587 0.68325867 0.6835913  0.68392373\n",
      " 0.68425598 0.68458804 0.6849199  0.68525159 0.68558308 0.68591438\n",
      " 0.68624549 0.68657642 0.68690715 0.6872377  0.68756805 0.68789822\n",
      " 0.68822819 0.68855797 0.68888756 0.68921696 0.68954617 0.68987518\n",
      " 0.69020401 0.69053264 0.69086108 0.69118933 0.69151738 0.69184524\n",
      " 0.69217291 0.69250038 0.69282766 0.69315475]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (1,) and (531, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-173-a5e57d4406cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_proba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"g-\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Iris-Versicolour\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_proba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"b--\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Not Iris-Versicolour\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_new\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecision_boundary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;31m#plt.plot([decision_boundary, decision_boundary], \"k:\", linewidth=2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/JI/miniconda2/lib/python2.7/site-packages/matplotlib/pyplot.pyc\u001b[0m in \u001b[0;36mplot\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   3316\u001b[0m                       mplDeprecation)\n\u001b[1;32m   3317\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3318\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3319\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3320\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/JI/miniconda2/lib/python2.7/site-packages/matplotlib/__init__.pyc\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1890\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[1;32m   1891\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1892\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1893\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1894\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/JI/miniconda2/lib/python2.7/site-packages/matplotlib/axes/_axes.pyc\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1404\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_alias_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1406\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1407\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1408\u001b[0m             \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/JI/miniconda2/lib/python2.7/site-packages/matplotlib/axes/_base.pyc\u001b[0m in \u001b[0;36m_grab_next_args\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    405\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mseg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mseg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/JI/miniconda2/lib/python2.7/site-packages/matplotlib/axes/_base.pyc\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'plot'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/JI/miniconda2/lib/python2.7/site-packages/matplotlib/axes/_base.pyc\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001b[0;32m--> 244\u001b[0;31m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (1,) and (531, 1)"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/h9KY0TZwUO7JgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1106db950>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predict model's estimated probabilities for flowers with petal lengths 1-7 cm\n",
    "X_new = np.linspace(1,7,1000).reshape(-1,1) # 1000x1 matrix of length 1-7\n",
    "y_proba = log_reg.predict_proba(X_new)\n",
    "print(y_proba[:,1])\n",
    "decision_boundary = X_new[y_proba[:, 1] >= 0.5][0]\n",
    "\n",
    "decision_boundary = X_new[y_proba[:, 1] >= 0.5]\n",
    "plt.plot(X_new, y_proba[:, 1], \"g-\", linewidth=2, label=\"Iris-Versicolour\")\n",
    "plt.plot(X_new, y_proba[:, 0], \"b--\", linewidth=2, label=\"Not Iris-Versicolour\")\n",
    "plt.plot(X_new[0],decision_boundary)\n",
    "#plt.plot([decision_boundary, decision_boundary], \"k:\", linewidth=2)\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.01457811 -4.23551451]]\n",
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [300, 150]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-162-9c5cc75629e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlog_reg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mlog_reg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mX_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0my_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_reg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/JI/miniconda2/lib/python2.7/site-packages/sklearn/linear_model/logistic.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=np.float64,\n\u001b[0;32m-> 1173\u001b[0;31m                          order=\"C\")\n\u001b[0m\u001b[1;32m   1174\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/JI/miniconda2/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/JI/miniconda2/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 181\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [300, 150]"
     ]
    }
   ],
   "source": [
    "X = iris[\"data\"][:,2:].reshape(-1,1)  # petal width\n",
    "print(X.shape)\n",
    "y = (iris[\"target\"] == 2).astype(np.int)  # 1 if Iris-Virginica, else 0\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression(random_state=42)\n",
    "log_reg.fit(X, y)\n",
    "X_new = np.linspace(0, 3, 1000).reshape(-1, 1)\n",
    "y_proba = log_reg.predict_proba(X_new)\n",
    "\n",
    "plt.plot(X_new, y_proba[:, 1], \"g-\", linewidth=2, label=\"Iris-Virginica\")\n",
    "plt.plot(X_new, y_proba[:, 0], \"b--\", linewidth=2, label=\"Not Iris-Virginica\")\n",
    "X.shape\n",
    "X_new = np.linspace(0, 3, 1000).reshape(-1, 1)\n",
    "y_proba = log_reg.predict_proba(X_new)\n",
    "decision_boundary = X_new[y_proba[:, 1] >= 0.5][0]\n",
    "\n",
    "plt.figure(figsize=(8, 3))\n",
    "plt.plot(X[y==0], y[y==0], \"bs\")\n",
    "plt.plot(X[y==1], y[y==1], \"g^\")\n",
    "plt.plot([decision_boundary, decision_boundary], [-1, 2], \"k:\", linewidth=2)\n",
    "plt.plot(X_new, y_proba[:, 1], \"g-\", linewidth=2, label=\"Iris-Virginica\")\n",
    "plt.plot(X_new, y_proba[:, 0], \"b--\", linewidth=2, label=\"Not Iris-Virginica\")\n",
    "plt.text(decision_boundary+0.02, 0.15, \"Decision  boundary\", fontsize=14, color=\"k\", ha=\"center\")\n",
    "plt.arrow(decision_boundary, 0.08, -0.3, 0, head_width=0.05, head_length=0.1, fc='b', ec='b')\n",
    "plt.arrow(decision_boundary, 0.92, 0.3, 0, head_width=0.05, head_length=0.1, fc='g', ec='g')\n",
    "plt.xlabel(\"Petal width (cm)\", fontsize=14)\n",
    "plt.ylabel(\"Probability\", fontsize=14)\n",
    "plt.legend(loc=\"center left\", fontsize=14)\n",
    "plt.axis([0, 3, -0.02, 1.02])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "Hands on ML\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
